{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf6f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_restful import Resource, Api\n",
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28640aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71ff676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(\"AkuruHuruwaApI\")\n",
    "cors = CORS(app)\n",
    "cors = CORS(app, origins=['http://localhost:3000'])\n",
    "api = Api(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9fd0d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2d5663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from a directory\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# Split documents into chunks\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "# Load OpenAI embeddings\n",
    "def load_embeddings():\n",
    "    client = openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    embeddings = OpenAIEmbeddings(model=\"ada\", client=client)\n",
    "    return embeddings\n",
    "\n",
    "# Initialize Pinecone index\n",
    "def init_index(docs, embeddings):\n",
    "    pinecone.init(api_key = os.getenv('PINECONE_API'), environment=\"asia-northeast1-gcp\")\n",
    "#     pinecone.init(api_key = 'f3493788-2a36-48ee-a2d3-f6205e2c71c0', environment=\"asia-northeast1-gcp\")\n",
    "    index_name = \"qabot2\"\n",
    "    index = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "    return index\n",
    "\n",
    "# Load language model\n",
    "def load_language_model():\n",
    "    client = openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    llm = OpenAI(model=\"text-davinci-003\", client=client)\n",
    "#     api_key = \"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\"\n",
    "#     llm = OpenAI(model=\"text-davinci-003\", openai_api_key=api_key)\n",
    "    return llm\n",
    "\n",
    "# Initialize question-answering chain\n",
    "def initialize_qa_chain(llm):\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    return chain\n",
    "\n",
    "# Load language model\n",
    "llm = load_language_model()\n",
    "\n",
    "# Initialize question-answering chain\n",
    "chain = initialize_qa_chain(llm)\n",
    "\n",
    "# Get similar documents based on a query\n",
    "def get_similar_docs(query, k=1, score=False):\n",
    "    if score:\n",
    "        similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "    else:\n",
    "        similar_docs = index.similarity_search(query, k=k)\n",
    "    return similar_docs\n",
    "\n",
    "def get_answer(query):\n",
    "    similar_docs = get_similar_docs(query)\n",
    "    answer = chain.run(input_documents=similar_docs, question=query)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f548c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path for documents\n",
    "# directory = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d80666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from the directory\n",
    "# documents = load_docs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deafc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks\n",
    "# docs = split_docs(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07811673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI embeddings\n",
    "# embeddings = load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45bcb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone index\n",
    "# index = init_index(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65447f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load language model\n",
    "# llm = load_language_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8947bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load question-answering chain\n",
    "# chain = load_qa_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef6ad74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer to a question\n",
    "\n",
    "# Define the API endpoint for answering questions\n",
    "@app.route('/answer', methods=['POST'])\n",
    "def answer_question():\n",
    "    # Get the query from the request data\n",
    "    query = request.json['query']\n",
    "    \n",
    "    # Call the get_answer function\n",
    "    answer = get_answer(query)\n",
    "    \n",
    "    # Return the answer as a JSON response\n",
    "    return jsonify({'answer': answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79dd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set the directory path for documents\n",
    "    directory = 'data'\n",
    "    # Load documents from the directory\n",
    "    documents = load_docs(directory)\n",
    "    # Split documents into chunks\n",
    "    docs = split_docs(documents)\n",
    "    # Load OpenAI embeddings\n",
    "    embeddings = load_embeddings()\n",
    "    # Initialize Pinecone index\n",
    "    index = init_index(docs, embeddings)\n",
    "    # Load language model\n",
    "    llm = load_language_model()\n",
    "    # Load question-answering chain\n",
    "    chain = load_qa_chain(llm)\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
